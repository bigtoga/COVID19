{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today $timestr value: \"20200401-045246\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint \n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from functools import reduce\n",
    "import time\n",
    "\n",
    "# Set to True if you want \"all the info messages\"\n",
    "debug = True;\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "if(debug):\n",
    "    print(f'Today $timestr value: \"{timestr}\"')\n",
    "\n",
    "baseFolder = '../data/Johns Hopkins/csse_covid_19_time_series/';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "\n",
    "## Time Series\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country     Date  Confirmed\n",
      "0  Afghanistan  1/22/20          0\n",
      "1      Albania  1/22/20          0\n",
      "2      Algeria  1/22/20          0\n",
      "3      Andorra  1/22/20          0\n",
      "4       Angola  1/22/20          0\n"
     ]
    }
   ],
   "source": [
    "# Ultimate goal: Get data in 3 column format: Date, Country, TotalConfirmedCasesThusFar\n",
    "\n",
    "# Step 1: Get the raw data - JHU adds a new column for each date\n",
    "raw_confirmed = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "df = pd.read_csv(raw_confirmed);\n",
    "\n",
    "# Step 2: Drop Province/State, Lat, and Long\n",
    "df = df.drop(df.columns[[0, 2, 3]], axis=1);\n",
    "\n",
    "# Step 3: Convert dates to invididual rows using melt()\n",
    "key_columns = df.columns.to_list()[:1]\n",
    "date_columns = df.columns.to_list()[1:]\n",
    "\n",
    "df_clean = pd.melt(\n",
    "    df\n",
    "    , id_vars=key_columns\n",
    "    , value_vars=date_columns\n",
    "    , var_name='Date'\n",
    "    , value_name='Confirmed'\n",
    ")\n",
    "\n",
    "# Step 4: Rename to make easier \n",
    "df_clean.columns = [\"Country\", \"Date\", \"Confirmed\"];\n",
    "\n",
    "if(debug):\n",
    "    print(df_clean.head());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country       Date  Confirmed\n",
      "0  Afghanistan 2020-01-22          0\n",
      "1  Afghanistan 2020-01-23          0\n",
      "2  Afghanistan 2020-01-24          0\n",
      "3  Afghanistan 2020-01-25          0\n",
      "4  Afghanistan 2020-01-26          0\n"
     ]
    }
   ],
   "source": [
    "# Step 5: group by\n",
    "dfAggs = df_clean.groupby(['Country', 'Date']).agg({\n",
    "        'Confirmed': [\n",
    "            np.sum\n",
    "        ]\n",
    "})\n",
    "\n",
    "# Convert from groupby object to dataframe:\n",
    "dfAggs = dfAggs.reset_index(level=['Country', 'Date'])\n",
    "\n",
    "# Flatten the index by renaming the columns\n",
    "dfAggs.columns = [\"Country\", \"Date\", \"Confirmed\"];\n",
    "dfAggs['Date'] = pd.to_datetime(dfAggs['Date']) \n",
    "dfAggs['Confirmed'] = pd.to_numeric(dfAggs['Confirmed'], downcast='integer')\n",
    "\n",
    "if(debug):\n",
    "    print(dfAggs.head());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country       Date  Confirmed\n",
      "11821      US 2020-03-03        118\n",
      "11824      US 2020-03-04        149\n",
      "11825      US 2020-03-05        217\n",
      "11826      US 2020-03-06        262\n",
      "11827      US 2020-03-07        402\n"
     ]
    }
   ],
   "source": [
    "# Normalize \"Day 1\" as first day that country had 100 confirmed cases:\n",
    "# Step 1: Remove all rows until a country has at least 100 rows\n",
    "dfFiltered = dfAggs[dfAggs[\"Confirmed\"] >= 100]\n",
    "dfFiltered = dfFiltered.sort_values([\"Country\", \"Date\"]);\n",
    "#dfFiltered = dfFiltered.set_index(\"Country\", \"Date\");\n",
    "\n",
    "if(debug):\n",
    "    print(dfFiltered[dfFiltered[\"Country\"] == 'US'].head());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country       Date  Confirmed  DayNum\n",
      "11821      US 2020-03-03        118       1\n",
      "11824      US 2020-03-04        149       2\n",
      "11825      US 2020-03-05        217       3\n",
      "11826      US 2020-03-06        262       4\n",
      "11827      US 2020-03-07        402       5\n",
      "11828      US 2020-03-08        518       6\n",
      "11829      US 2020-03-09        583       7\n",
      "11800      US 2020-03-10        959       8\n",
      "11801      US 2020-03-11       1281       9\n",
      "11802      US 2020-03-12       1663      10\n",
      "11803      US 2020-03-13       2179      11\n",
      "11804      US 2020-03-14       2727      12\n",
      "11805      US 2020-03-15       3499      13\n",
      "11806      US 2020-03-16       4632      14\n",
      "11807      US 2020-03-17       6421      15\n",
      "11808      US 2020-03-18       7783      16\n",
      "11809      US 2020-03-19      13677      17\n",
      "11811      US 2020-03-20      19100      18\n",
      "11812      US 2020-03-21      25489      19\n",
      "11813      US 2020-03-22      33276      20\n",
      "11814      US 2020-03-23      43847      21\n",
      "11815      US 2020-03-24      53740      22\n",
      "11816      US 2020-03-25      65778      23\n",
      "11817      US 2020-03-26      83836      24\n",
      "11818      US 2020-03-27     101657      25\n",
      "11819      US 2020-03-28     121478      26\n",
      "11820      US 2020-03-29     140886      27\n",
      "11822      US 2020-03-30     161807      28\n",
      "11823      US 2020-03-31     188172      29\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Add another layer of aggregation - cumulative count - so that we can sequentially\n",
    "#         order each row (i.e. \"Which date was Day 1 for each country?\")\n",
    "dfFiltered['DayNum'] = dfFiltered.groupby('Country').cumcount() + 1;\n",
    "if(debug):\n",
    "    print(dfFiltered[dfFiltered[\"Country\"] == 'US']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target dataframe column format\n",
    "1. 2000-01-01, 'Coca-Cola', '72537'\n",
    "2. 2000-01-01, 'Microsoft', '70196'\n",
    "\n",
    "### Target json data format: \n",
    "1. {date: 2000-01-01, name: \"Coca-Cola\", category: \"Beverages\", value: 72537}\n",
    "2. {date: 2000-01-01, name: \"Microsoft\", category: \"Technology\", value: 70196}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country       Date  Confirmed  DayNum\n",
      "1653   Brazil 2020-03-13        151       1\n",
      "1654   Brazil 2020-03-14        151       2\n",
      "1655   Brazil 2020-03-15        162       3\n",
      "1656   Brazil 2020-03-16        200       4\n",
      "1657   Brazil 2020-03-17        321       5\n",
      "1658   Brazil 2020-03-18        372       6\n",
      "1659   Brazil 2020-03-19        621       7\n",
      "1661   Brazil 2020-03-20        793       8\n",
      "1662   Brazil 2020-03-21       1021       9\n",
      "1663   Brazil 2020-03-22       1546      10\n",
      "1664   Brazil 2020-03-23       1924      11\n",
      "1665   Brazil 2020-03-24       2247      12\n",
      "1666   Brazil 2020-03-25       2554      13\n",
      "1667   Brazil 2020-03-26       2985      14\n",
      "1668   Brazil 2020-03-27       3417      15\n",
      "1669   Brazil 2020-03-28       3904      16\n",
      "1670   Brazil 2020-03-29       4256      17\n",
      "1672   Brazil 2020-03-30       4579      18\n",
      "1673   Brazil 2020-03-31       5717      19\n",
      "2281   Canada 2020-03-11        108       1\n",
      "2282   Canada 2020-03-12        117       2\n",
      "2283   Canada 2020-03-13        193       3\n",
      "2284   Canada 2020-03-14        198       4\n",
      "2285   Canada 2020-03-15        252       5\n",
      "2286   Canada 2020-03-16        415       6\n",
      "2287   Canada 2020-03-17        478       7\n",
      "2288   Canada 2020-03-18        657       8\n",
      "2289   Canada 2020-03-19        800       9\n",
      "2291   Canada 2020-03-20        943      10\n",
      "2292   Canada 2020-03-21       1277      11\n",
      "...       ...        ...        ...     ...\n",
      "10773   Spain 2020-03-31      95923      30\n",
      "11821      US 2020-03-03        118       1\n",
      "11824      US 2020-03-04        149       2\n",
      "11825      US 2020-03-05        217       3\n",
      "11826      US 2020-03-06        262       4\n",
      "11827      US 2020-03-07        402       5\n",
      "11828      US 2020-03-08        518       6\n",
      "11829      US 2020-03-09        583       7\n",
      "11800      US 2020-03-10        959       8\n",
      "11801      US 2020-03-11       1281       9\n",
      "11802      US 2020-03-12       1663      10\n",
      "11803      US 2020-03-13       2179      11\n",
      "11804      US 2020-03-14       2727      12\n",
      "11805      US 2020-03-15       3499      13\n",
      "11806      US 2020-03-16       4632      14\n",
      "11807      US 2020-03-17       6421      15\n",
      "11808      US 2020-03-18       7783      16\n",
      "11809      US 2020-03-19      13677      17\n",
      "11811      US 2020-03-20      19100      18\n",
      "11812      US 2020-03-21      25489      19\n",
      "11813      US 2020-03-22      33276      20\n",
      "11814      US 2020-03-23      43847      21\n",
      "11815      US 2020-03-24      53740      22\n",
      "11816      US 2020-03-25      65778      23\n",
      "11817      US 2020-03-26      83836      24\n",
      "11818      US 2020-03-27     101657      25\n",
      "11819      US 2020-03-28     121478      26\n",
      "11820      US 2020-03-29     140886      27\n",
      "11822      US 2020-03-30     161807      28\n",
      "11823      US 2020-03-31     188172      29\n",
      "\n",
      "[235 rows x 4 columns]\n",
      "[{\"Country\":\"Brazil\",\"Date\":\"2020-03-13T00:00:00Z\",\"Confirmed\":151,\"DayNum\":1},{\"Country\":\"Brazil\",\"Date\":\"2020-03-14T00:00:00Z\",\"Confirmed\":151,\"DayNum\":2},{\"Country\":\"Brazil\",\"Date\":\"2020-03-15T00:00:00Z\",\"Confirmed\":162,\"DayNum\":3},{\"Country\":\"Brazil\",\"Date\":\"2020-03-16T00:00:00Z\",\"Confirmed\":200,\"DayNum\":4},{\"Country\":\"Brazil\",\"Date\":\"2020-03-17T00:00:00Z\",\"Confirmed\":321,\"DayNum\":5}]\n"
     ]
    }
   ],
   "source": [
    "countries_to_view = ['US', 'Canada', 'Brazil', 'Spain', 'Mexico', 'India', 'China', 'Iran']\n",
    "\n",
    "mask = dfFiltered['Country'].isin(countries_to_view)\n",
    "dfFiltered.sort_values(['Country'])\n",
    "print(dfFiltered[mask]);\n",
    "# orient 'records' creates one element per row w no index value \n",
    "print(dfFiltered[mask].head().to_json(orient='records', date_format='iso', date_unit='s'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data as of 20200331-000000\n",
      "JSON file written to ../data/Johns Hopkins/csse_covid_19_time_series/timeseries_20200331-000000.json\n",
      "CSV file written to ../data/Johns Hopkins/csse_covid_19_time_series/timeseries_20200331-000000.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent date:\n",
    "maxdate = dfFiltered[\"Date\"].max().strftime(\"%Y%m%d-%H%M%S\");\n",
    "print(f'Data as of {maxdate}');\n",
    "\n",
    "# Export to file\n",
    "jsonFile = 'timeseries_' + str(maxdate) + '.json';\n",
    "finalFile = baseFolder + jsonFile;\n",
    "dfFiltered[mask].to_json(finalFile, orient='records', date_format='iso', date_unit='s');\n",
    "print(f'JSON file written to {finalFile}');\n",
    "\n",
    "finalFile = finalFile.replace('.json', '.csv');\n",
    "dfFiltered[mask].to_csv(finalFile, index = False);\n",
    "print(f'CSV file written to {finalFile}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done - now go use the json file in d3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
