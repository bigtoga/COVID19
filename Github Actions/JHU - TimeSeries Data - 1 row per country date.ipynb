{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today $timestr value: \"20200403-164710\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint \n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from functools import reduce\n",
    "import time\n",
    "\n",
    "# Set to True if you want \"all the info messages\"\n",
    "debug = True;\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "if(debug):\n",
    "    print(f'Today $timestr value: \"{timestr}\"')\n",
    "\n",
    "baseFolder = '../data/Johns Hopkins/csse_covid_19_time_series/';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "\n",
    "## Time Series\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country     Date  Confirmed\n",
      "0  Afghanistan  1/22/20          0\n",
      "1      Albania  1/22/20          0\n",
      "2      Algeria  1/22/20          0\n",
      "3      Andorra  1/22/20          0\n",
      "4       Angola  1/22/20          0\n"
     ]
    }
   ],
   "source": [
    "# Ultimate goal: Get data in 3 column format: Date, Country, TotalConfirmedCasesThusFar\n",
    "\n",
    "# Step 1: Get the raw data - JHU adds a new column for each date\n",
    "raw_confirmed = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "df = pd.read_csv(raw_confirmed);\n",
    "\n",
    "# Step 2: Drop Province/State, Lat, and Long\n",
    "df = df.drop(df.columns[[0, 2, 3]], axis=1);\n",
    "\n",
    "# Step 3: Convert dates to invididual rows using melt()\n",
    "key_columns = df.columns.to_list()[:1]\n",
    "date_columns = df.columns.to_list()[1:]\n",
    "\n",
    "df_clean = pd.melt(\n",
    "    df\n",
    "    , id_vars=key_columns\n",
    "    , value_vars=date_columns\n",
    "    , var_name='Date'\n",
    "    , value_name='Confirmed'\n",
    ")\n",
    "\n",
    "# Step 4: Rename to make easier \n",
    "df_clean.columns = [\"Country\", \"Date\", \"Confirmed\"];\n",
    "\n",
    "if(debug):\n",
    "    print(df_clean.head());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country       Date  Confirmed\n",
      "0  Afghanistan 2020-01-22          0\n",
      "1  Afghanistan 2020-01-23          0\n",
      "2  Afghanistan 2020-01-24          0\n",
      "3  Afghanistan 2020-01-25          0\n",
      "4  Afghanistan 2020-01-26          0\n"
     ]
    }
   ],
   "source": [
    "# Step 5: group by\n",
    "dfAggs = df_clean.groupby(['Country', 'Date']).agg({\n",
    "        'Confirmed': [\n",
    "            np.sum\n",
    "        ]\n",
    "})\n",
    "\n",
    "# Convert from groupby object to dataframe:\n",
    "dfAggs = dfAggs.reset_index(level=['Country', 'Date'])\n",
    "\n",
    "# Flatten the index by renaming the columns\n",
    "dfAggs.columns = [\"Country\", \"Date\", \"Confirmed\"];\n",
    "dfAggs['Date'] = pd.to_datetime(dfAggs['Date']) \n",
    "dfAggs['Confirmed'] = pd.to_numeric(dfAggs['Confirmed'], downcast='integer')\n",
    "\n",
    "if(debug):\n",
    "    print(dfAggs.head());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country       Date  Confirmed\n",
      "12229      US 2020-03-03        118\n",
      "12232      US 2020-03-04        149\n",
      "12233      US 2020-03-05        217\n",
      "12234      US 2020-03-06        262\n",
      "12235      US 2020-03-07        402\n"
     ]
    }
   ],
   "source": [
    "# Normalize \"Day 1\" as first day that country had 100 confirmed cases:\n",
    "# Step 1: Remove all rows until a country has at least 100 rows\n",
    "dfFiltered = dfAggs[dfAggs[\"Confirmed\"] >= 100]\n",
    "dfFiltered = dfFiltered.sort_values([\"Country\", \"Date\"]);\n",
    "#dfFiltered = dfFiltered.set_index(\"Country\", \"Date\");\n",
    "\n",
    "if(debug):\n",
    "    print(dfFiltered[dfFiltered[\"Country\"] == 'US'].head());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country       Date  Confirmed  DayNum\n",
      "12229      US 2020-03-03        118       1\n",
      "12232      US 2020-03-04        149       2\n",
      "12233      US 2020-03-05        217       3\n",
      "12234      US 2020-03-06        262       4\n",
      "12235      US 2020-03-07        402       5\n",
      "12236      US 2020-03-08        518       6\n",
      "12237      US 2020-03-09        583       7\n",
      "12208      US 2020-03-10        959       8\n",
      "12209      US 2020-03-11       1281       9\n",
      "12210      US 2020-03-12       1663      10\n",
      "12211      US 2020-03-13       2179      11\n",
      "12212      US 2020-03-14       2727      12\n",
      "12213      US 2020-03-15       3499      13\n",
      "12214      US 2020-03-16       4632      14\n",
      "12215      US 2020-03-17       6421      15\n",
      "12216      US 2020-03-18       7783      16\n",
      "12217      US 2020-03-19      13677      17\n",
      "12219      US 2020-03-20      19100      18\n",
      "12220      US 2020-03-21      25489      19\n",
      "12221      US 2020-03-22      33276      20\n",
      "12222      US 2020-03-23      43847      21\n",
      "12223      US 2020-03-24      53740      22\n",
      "12224      US 2020-03-25      65778      23\n",
      "12225      US 2020-03-26      83836      24\n",
      "12226      US 2020-03-27     101657      25\n",
      "12227      US 2020-03-28     121478      26\n",
      "12228      US 2020-03-29     140886      27\n",
      "12230      US 2020-03-30     161807      28\n",
      "12231      US 2020-03-31     188172      29\n",
      "12238      US 2020-04-01     213372      30\n",
      "12239      US 2020-04-02     243453      31\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Add another layer of aggregation - cumulative count - so that we can sequentially\n",
    "#         order each row (i.e. \"Which date was Day 1 for each country?\")\n",
    "dfFiltered['DayNum'] = dfFiltered.groupby('Country').cumcount() + 1;\n",
    "if(debug):\n",
    "    print(dfFiltered[dfFiltered[\"Country\"] == 'US']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target dataframe column format\n",
    "1. 2000-01-01, 'Coca-Cola', '72537'\n",
    "2. 2000-01-01, 'Microsoft', '70196'\n",
    "\n",
    "### Target json data format: \n",
    "1. {date: 2000-01-01, name: \"Coca-Cola\", category: \"Beverages\", value: 72537}\n",
    "2. {date: 2000-01-01, name: \"Microsoft\", category: \"Technology\", value: 70196}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country       Date  Confirmed  DayNum\n",
      "1699   Brazil 2020-03-13        151       1\n",
      "1700   Brazil 2020-03-14        151       2\n",
      "1701   Brazil 2020-03-15        162       3\n",
      "1702   Brazil 2020-03-16        200       4\n",
      "1703   Brazil 2020-03-17        321       5\n",
      "1704   Brazil 2020-03-18        372       6\n",
      "1705   Brazil 2020-03-19        621       7\n",
      "1707   Brazil 2020-03-20        793       8\n",
      "1708   Brazil 2020-03-21       1021       9\n",
      "1709   Brazil 2020-03-22       1546      10\n",
      "1710   Brazil 2020-03-23       1924      11\n",
      "1711   Brazil 2020-03-24       2247      12\n",
      "1712   Brazil 2020-03-25       2554      13\n",
      "1713   Brazil 2020-03-26       2985      14\n",
      "1714   Brazil 2020-03-27       3417      15\n",
      "1715   Brazil 2020-03-28       3904      16\n",
      "1716   Brazil 2020-03-29       4256      17\n",
      "1718   Brazil 2020-03-30       4579      18\n",
      "1719   Brazil 2020-03-31       5717      19\n",
      "1726   Brazil 2020-04-01       6836      20\n",
      "1727   Brazil 2020-04-02       8044      21\n",
      "2345   Canada 2020-03-11        108       1\n",
      "2346   Canada 2020-03-12        117       2\n",
      "2347   Canada 2020-03-13        193       3\n",
      "2348   Canada 2020-03-14        198       4\n",
      "2349   Canada 2020-03-15        252       5\n",
      "2350   Canada 2020-03-16        415       6\n",
      "2351   Canada 2020-03-17        478       7\n",
      "2352   Canada 2020-03-18        657       8\n",
      "2353   Canada 2020-03-19        800       9\n",
      "...       ...        ...        ...     ...\n",
      "12232      US 2020-03-04        149       2\n",
      "12233      US 2020-03-05        217       3\n",
      "12234      US 2020-03-06        262       4\n",
      "12235      US 2020-03-07        402       5\n",
      "12236      US 2020-03-08        518       6\n",
      "12237      US 2020-03-09        583       7\n",
      "12208      US 2020-03-10        959       8\n",
      "12209      US 2020-03-11       1281       9\n",
      "12210      US 2020-03-12       1663      10\n",
      "12211      US 2020-03-13       2179      11\n",
      "12212      US 2020-03-14       2727      12\n",
      "12213      US 2020-03-15       3499      13\n",
      "12214      US 2020-03-16       4632      14\n",
      "12215      US 2020-03-17       6421      15\n",
      "12216      US 2020-03-18       7783      16\n",
      "12217      US 2020-03-19      13677      17\n",
      "12219      US 2020-03-20      19100      18\n",
      "12220      US 2020-03-21      25489      19\n",
      "12221      US 2020-03-22      33276      20\n",
      "12222      US 2020-03-23      43847      21\n",
      "12223      US 2020-03-24      53740      22\n",
      "12224      US 2020-03-25      65778      23\n",
      "12225      US 2020-03-26      83836      24\n",
      "12226      US 2020-03-27     101657      25\n",
      "12227      US 2020-03-28     121478      26\n",
      "12228      US 2020-03-29     140886      27\n",
      "12230      US 2020-03-30     161807      28\n",
      "12231      US 2020-03-31     188172      29\n",
      "12238      US 2020-04-01     213372      30\n",
      "12239      US 2020-04-02     243453      31\n",
      "\n",
      "[251 rows x 4 columns]\n",
      "[{\"Country\":\"Brazil\",\"Date\":\"2020-03-13T00:00:00Z\",\"Confirmed\":151,\"DayNum\":1},{\"Country\":\"Brazil\",\"Date\":\"2020-03-14T00:00:00Z\",\"Confirmed\":151,\"DayNum\":2},{\"Country\":\"Brazil\",\"Date\":\"2020-03-15T00:00:00Z\",\"Confirmed\":162,\"DayNum\":3},{\"Country\":\"Brazil\",\"Date\":\"2020-03-16T00:00:00Z\",\"Confirmed\":200,\"DayNum\":4},{\"Country\":\"Brazil\",\"Date\":\"2020-03-17T00:00:00Z\",\"Confirmed\":321,\"DayNum\":5}]\n"
     ]
    }
   ],
   "source": [
    "countries_to_view = ['US', 'Canada', 'Brazil', 'Spain', 'Mexico', 'India', 'China', 'Iran']\n",
    "\n",
    "mask = dfFiltered['Country'].isin(countries_to_view)\n",
    "dfFiltered.sort_values(['Country'])\n",
    "print(dfFiltered[mask]);\n",
    "# orient 'records' creates one element per row w no index value \n",
    "print(dfFiltered[mask].head().to_json(orient='records', date_format='iso', date_unit='s'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data as of 20200402-000000\n",
      "JSON file written to ../data/Johns Hopkins/csse_covid_19_time_series/timeseries_20200402-000000.json\n",
      "CSV file written to ../data/Johns Hopkins/csse_covid_19_time_series/timeseries_20200402-000000.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent date:\n",
    "maxdate = dfFiltered[\"Date\"].max().strftime(\"%Y%m%d-%H%M%S\");\n",
    "print(f'Data as of {maxdate}');\n",
    "\n",
    "# Export to file\n",
    "jsonFile = 'timeseries_' + str(maxdate) + '.json';\n",
    "finalFile = baseFolder + jsonFile;\n",
    "dfFiltered[mask].to_json(finalFile, orient='records', date_format='iso', date_unit='s');\n",
    "print(f'JSON file written to {finalFile}');\n",
    "\n",
    "finalFile = finalFile.replace('.json', '.csv');\n",
    "dfFiltered[mask].to_csv(finalFile, index = False);\n",
    "print(f'CSV file written to {finalFile}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done - now go use the json file in d3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
