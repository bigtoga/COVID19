{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint \n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from functools import reduce\n",
    "import time\n",
    "\n",
    "# Set to True if you want \"all the info messages\"\n",
    "debug = False;\n",
    "\n",
    "baseFolder = '../data/Johns Hopkins/csse_covid_19_daily_reports/';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "\n",
    "## Daily Reports - example of how to get the most recent CSV\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: 04-02-2020.csv\n"
     ]
    }
   ],
   "source": [
    "baseUrl = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "\n",
    "# Step 1: Get the latest file\n",
    "todaysDate = time.strftime(\"%m-%d-%Y\")\n",
    "todaysFile = todaysDate + \".csv\"\n",
    "dataUrl = baseUrl + todaysFile\n",
    "finalFile = dataUrl;\n",
    "shortFile = todaysFile;\n",
    "\n",
    "if(debug):\n",
    "    print(f'Trying \"{todaysFile}\"...');\n",
    "    \n",
    "response = requests.head(dataUrl, timeout=5);\n",
    "status_code = response.status_code;\n",
    "reason = response.reason;\n",
    "\n",
    "if(status_code != 200):\n",
    "    if(debug):\n",
    "        print('.... error - 404 not found. Looking for yesterday file');\n",
    "\n",
    "    days_to_subtract = 1;\n",
    "    yestDate = datetime.today() - timedelta(days=days_to_subtract);\n",
    "    yestDate = yestDate.strftime(\"%m-%d-%Y\");\n",
    "    yestFile = yestDate + \".csv\";\n",
    "    dataUrl = baseUrl + yestFile;\n",
    "    shortFile = yestFile;\n",
    "\n",
    "    if(debug):\n",
    "        print(f'Trying \"{yestFile}\"...');\n",
    "    response = requests.head(dataUrl, timeout=5);\n",
    "    status_code = response.status_code;\n",
    "    reason = response.reason;\n",
    "    \n",
    "    if(status_code != 200):\n",
    "        finalFile = \"\";\n",
    "        if(debug):\n",
    "            print(f'... Error! Unable to find yesterday file also');\n",
    "    else:\n",
    "        finalFile = dataUrl;\n",
    "        if(debug):\n",
    "            print('... Successfully found yesterday file');\n",
    "\n",
    "if(debug):\n",
    "    print('---------------------------------------');\n",
    "print(f'File found: {shortFile}');\n",
    "if(debug):\n",
    "    print('---------------------------------------');\n",
    "\n",
    "df = pd.read_csv(finalFile);\n",
    "\n",
    "# Get rid of columns we don't want:\n",
    "df = df.drop(df.columns[[0, 1, 2, 5, 6, 8, 9, 10, 11]], axis=1)\n",
    "\n",
    "# Rename to make easier\n",
    "df.columns = [\"Country\", \"Date\", \"ConfirmedCases\"];\n",
    "\n",
    "# Convert from string \"2020-03-26 23:48:35\" to just the date only\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='raise')\n",
    "df['Date'] = df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data as of 2020-04-02\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent date:\n",
    "maxdate = df[\"Date\"].max();\n",
    "print(f'Data as of {maxdate}');\n",
    "\n",
    "# Delete rows older than this - China, in particular, has \"extra\" rows\n",
    "start_rows = df.size;\n",
    "df = df[(df['Date']>= maxdate)];\n",
    "before_groupby_rows = df.size;\n",
    "\n",
    "if(debug):\n",
    "    print(f'   - original rows: {start_rows}');\n",
    "    print(f'   - after removing \"old\" rows: {before_groupby_rows}');\n",
    "    df[df[\"Country\"] == 'China']; # 3/31 - I swear! I saw some \"weird\" data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country        Date  ConfirmedCases\n",
      "23   Brazil  2020-04-02            8044\n",
      "32   Canada  2020-04-02           11284\n",
      "36    China  2020-04-02           77021\n",
      "78    India  2020-04-02            2543\n",
      "80     Iran  2020-04-02           50468\n",
      "111  Mexico  2020-04-02            1378\n",
      "154   Spain  2020-04-02          112065\n",
      "169      US  2020-04-02          243453\n"
     ]
    }
   ],
   "source": [
    "# Ultimate goal: Get data in 3 column format: Date, Country, ConfirmedCases\n",
    "\n",
    "# Group by Country\n",
    "dfAggs = df.groupby(['Country', 'Date']).agg({\n",
    "        'ConfirmedCases': [\n",
    "            np.sum\n",
    "        ]\n",
    "})\n",
    "\n",
    "# Convert from groupby object to dataframe:\n",
    "dfAggs = dfAggs.reset_index(level=['Country', 'Date'])\n",
    "\n",
    "# Flatten the index by renaming the columns\n",
    "dfAggs.columns = [\"Country\", \"Date\", \"ConfirmedCases\"];\n",
    "\n",
    "countries_to_view = ['US', 'Canada', 'Brazil', 'Spain', 'Mexico', 'India', 'China', 'Iran']\n",
    "    \n",
    "# Create a mask:\n",
    "mask = dfAggs['Country'].isin(countries_to_view)\n",
    "dfAggs.sort_values(['Country'])\n",
    "print(dfAggs[mask]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Country\":\"Brazil\",\"Date\":\"2020-04-02T00:00:00Z\",\"ConfirmedCases\":8044},{\"Country\":\"Canada\",\"Date\":\"2020-04-02T00:00:00Z\",\"ConfirmedCases\":11284},{\"Country\":\"China\",\"Date\":\"2020-04-02T00:00:00Z\",\"ConfirmedCases\":77021},{\"Country\":\"India\",\"Date\":\"2020-04-02T00:00:00Z\",\"ConfirmedCases\":2543},{\"Country\":\"Iran\",\"Date\":\"2020-04-02T00:00:00Z\",\"ConfirmedCases\":50468}]\n"
     ]
    }
   ],
   "source": [
    "# orient 'records' creates one element per row w no index value \n",
    "print(dfAggs[mask].head().to_json(orient='records', date_format='iso', date_unit='s'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file written to ../data/Johns Hopkins/csse_covid_19_daily_reports/confirmedCases_2020-04-02.json\n"
     ]
    }
   ],
   "source": [
    "# Export to file\n",
    "jsonFile = 'confirmedCases_' + str(maxdate) + '.json';\n",
    "finalFile = baseFolder + jsonFile;\n",
    "dfAggs[mask].to_json(finalFile, orient='records', date_format='iso', date_unit='s');\n",
    "print(f'Final file written to {finalFile}');\n",
    "\n",
    "# https://jsonformatter.curiousconcept.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done - now go use the json file in d3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
