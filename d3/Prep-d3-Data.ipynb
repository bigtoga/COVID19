{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint \n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from functools import reduce\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Johns Hopkins Universtiry (JHU) github data\n",
    "Two sets: \n",
    "1. Daily Reports\n",
    "2. Time Series\n",
    "\n",
    "https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "### A few notes:\n",
    "1. All dates in the \"current\" are UTC\n",
    "\n",
    "## Daily Reports \n",
    "https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports\n",
    "\n",
    "**What**: Each file has 1 row that contains total cumulative totals from Jan 22 through this date\\\n",
    "**Keys**: Admin2 (city), Province_State, Country_Region\\\n",
    "**Update freq**: Daily\\\n",
    "**Use when**: \n",
    "1. You only care about \"right now\", as in \"What are the cumulative counts right now?\" \n",
    "2. You plot current/specific day's case numbers by either City/State/Country, State/Country, or Country\n",
    "2. You want to map / chloropleth (inc. lat/long)\n",
    "\n",
    "What: A count of the confirmed cases/deaths/recoveries from Nov 1, 2019 up until this date\\\n",
    "Granularity: City => State/Province => Country\\\n",
    "\n",
    "## Time Series\n",
    "**What**: 1 row per Province/State, Country and 1 column per day since Jan 22 that contains that day's counts. Separate files for confirmed, deaths, recoveries.  \\\n",
    "**Keys**: State/Province, Country\\\n",
    "**Use when**: \n",
    "1. You want to plot daily case numbers by State/Province and/or Country\n",
    "2. You want to map / chloropleth (inc. lat/long)\n",
    "* Example: On March 26, the March 25 csv had 66 columns - the 4 \"keys\" and 62 separate columns b/c there have have been 62 total days passed since Jan 22\n",
    "\n",
    "## Archived - Daily Reports\n",
    "**What**: \\\n",
    "**Keys**: \\\n",
    "**Use when**: \n",
    "\n",
    "## Archived - Time Series\n",
    "https://github.com/CSSEGISandData/COVID-19/tree/master/archived_data/archived_time_series\n",
    "\n",
    "**What**: 1 row per City/State/Country and 1 column per day since Jan 22 that contains that day's counts\\\n",
    "**Keys**: State/Province, Country\\\n",
    "**Use when**: \n",
    "1. You want to plot daily case numbers by State and/or Country\n",
    "2. You want to map / chloropleth (inc. lat/long)\n",
    "* Example: On March 26, the March 25 csv had 66 columns - the 4 \"keys\" and 62 separate columns b/c there have have been 62 total days passed since Jan 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                    Province/State         Country/Region      Lat      Long  \\\n",
       "0                             NaN               Thailand  15.0000  101.0000   \n",
       "1                             NaN                  Japan  36.0000  138.0000   \n",
       "2                             NaN              Singapore   1.2833  103.8333   \n",
       "3                             NaN                  Nepal  28.1667   84.2500   \n",
       "4                             NaN               Malaysia   2.5000  112.5000   \n",
       "5                British Columbia                 Canada  49.2827 -123.1207   \n",
       "6                 New South Wales              Australia -33.8688  151.2093   \n",
       "7                        Victoria              Australia -37.8136  144.9631   \n",
       "8                      Queensland              Australia -28.0167  153.4000   \n",
       "9                             NaN               Cambodia  11.5500  104.9167   \n",
       "10                            NaN              Sri Lanka   7.0000   81.0000   \n",
       "11                            NaN                Germany  51.0000    9.0000   \n",
       "12                            NaN                Finland  64.0000   26.0000   \n",
       "13                            NaN   United Arab Emirates  24.0000   54.0000   \n",
       "14                            NaN            Philippines  13.0000  122.0000   \n",
       "15                            NaN                  India  21.0000   78.0000   \n",
       "16                            NaN                  Italy  43.0000   12.0000   \n",
       "17                            NaN                 Sweden  63.0000   16.0000   \n",
       "18                            NaN                  Spain  40.0000   -4.0000   \n",
       "19                South Australia              Australia -34.9285  138.6007   \n",
       "20                            NaN                Belgium  50.8333    4.0000   \n",
       "21                            NaN                  Egypt  26.0000   30.0000   \n",
       "22          From Diamond Princess              Australia  35.4437  139.6380   \n",
       "23                            NaN                Lebanon  33.8547   35.8623   \n",
       "24                            NaN                   Iraq  33.0000   44.0000   \n",
       "25                            NaN                   Oman  21.0000   57.0000   \n",
       "26                            NaN            Afghanistan  33.0000   65.0000   \n",
       "27                            NaN                Bahrain  26.0275   50.5500   \n",
       "28                            NaN                 Kuwait  29.5000   47.7500   \n",
       "29                            NaN                Algeria  28.0339    1.6596   \n",
       "..                            ...                    ...      ...       ...   \n",
       "471                           NaN             Cabo Verde  16.5388  -23.0418   \n",
       "472                  Sint Maarten            Netherlands  18.0425  -63.0548   \n",
       "473                           NaN                  Niger  17.6078    8.0817   \n",
       "474                           NaN       Papua New Guinea  -6.3150  143.9555   \n",
       "475                   Isle of Man         United Kingdom  54.2361   -4.5481   \n",
       "476                           NaN               Zimbabwe -20.0000   30.0000   \n",
       "477         Northwest Territories                 Canada  64.8255 -124.8457   \n",
       "478                           NaN             Cape Verde  15.1111  -23.6167   \n",
       "479                           NaN             East Timor  -8.5500  125.5600   \n",
       "480                           NaN                Eritrea  15.1794   39.7823   \n",
       "481                           NaN                 Uganda   1.0000   32.0000   \n",
       "482                           NaN               Dominica  15.4150  -61.3710   \n",
       "483                           NaN                Grenada  12.1165  -61.6790   \n",
       "484                           NaN             Mozambique -18.6657   35.5296   \n",
       "485                           NaN                  Syria  34.8021   38.9968   \n",
       "486                           NaN            Timor-Leste  -8.8742  125.7275   \n",
       "487                           NaN             Guadeloupe  16.2650  -61.5510   \n",
       "488                           NaN                Reunion -21.1151   55.5364   \n",
       "489                           NaN          French Guiana   3.9339  -53.1258   \n",
       "490                           NaN                Mayotte -12.8275   45.1662   \n",
       "491  United States Virgin Islands                     US  18.3358  -64.8963   \n",
       "492                            US                     US  37.0902  -95.7129   \n",
       "493                           NaN              Greenland  72.0000  -40.0000   \n",
       "494                           NaN                   Guam  13.4443  144.7937   \n",
       "495                           NaN               Guernsey  49.4500   -2.5800   \n",
       "496                           NaN                 Jersey  49.1900   -2.1100   \n",
       "497                           NaN            Puerto Rico  18.2000  -66.5000   \n",
       "498                           NaN  Republic of the Congo  -1.4400   15.5560   \n",
       "499                           NaN            The Bahamas  24.2500  -76.0000   \n",
       "500                           NaN             The Gambia  13.4667  -16.6000   \n",
       "\n",
       "     1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  ...  3/14/20  \\\n",
       "0          2        3        5        7        8        8  ...       82   \n",
       "1          2        1        2        2        4        4  ...      773   \n",
       "2          0        1        3        3        4        5  ...      212   \n",
       "3          0        0        0        1        1        1  ...        1   \n",
       "4          0        0        0        3        4        4  ...      238   \n",
       "5          0        0        0        0        0        0  ...       64   \n",
       "6          0        0        0        0        3        4  ...      112   \n",
       "7          0        0        0        0        1        1  ...       49   \n",
       "8          0        0        0        0        0        0  ...       46   \n",
       "9          0        0        0        0        0        1  ...        7   \n",
       "10         0        0        0        0        0        1  ...       10   \n",
       "11         0        0        0        0        0        1  ...     4585   \n",
       "12         0        0        0        0        0        0  ...      225   \n",
       "13         0        0        0        0        0        0  ...       85   \n",
       "14         0        0        0        0        0        0  ...      111   \n",
       "15         0        0        0        0        0        0  ...      102   \n",
       "16         0        0        0        0        0        0  ...    21157   \n",
       "17         0        0        0        0        0        0  ...      961   \n",
       "18         0        0        0        0        0        0  ...     6391   \n",
       "19         0        0        0        0        0        0  ...       19   \n",
       "20         0        0        0        0        0        0  ...      689   \n",
       "21         0        0        0        0        0        0  ...      109   \n",
       "22         0        0        0        0        0        0  ...        0   \n",
       "23         0        0        0        0        0        0  ...       93   \n",
       "24         0        0        0        0        0        0  ...      110   \n",
       "25         0        0        0        0        0        0  ...       19   \n",
       "26         0        0        0        0        0        0  ...       11   \n",
       "27         0        0        0        0        0        0  ...      210   \n",
       "28         0        0        0        0        0        0  ...      104   \n",
       "29         0        0        0        0        0        0  ...       37   \n",
       "..       ...      ...      ...      ...      ...      ...  ...      ...   \n",
       "471        0        0        0        0        0        0  ...        0   \n",
       "472        0        0        0        0        0        0  ...        0   \n",
       "473        0        0        0        0        0        0  ...        0   \n",
       "474        0        0        0        0        0        0  ...        0   \n",
       "475        0        0        0        0        0        0  ...        0   \n",
       "476        0        0        0        0        0        0  ...        0   \n",
       "477        0        0        0        0        0        0  ...        0   \n",
       "478        0        0        0        0        0        0  ...        0   \n",
       "479        0        0        0        0        0        0  ...        0   \n",
       "480        0        0        0        0        0        0  ...        0   \n",
       "481        0        0        0        0        0        0  ...        0   \n",
       "482        0        0        0        0        0        0  ...        0   \n",
       "483        0        0        0        0        0        0  ...        0   \n",
       "484        0        0        0        0        0        0  ...        0   \n",
       "485        0        0        0        0        0        0  ...        0   \n",
       "486        0        0        0        0        0        0  ...        0   \n",
       "487        0        0        0        0        0        0  ...        0   \n",
       "488        0        0        0        0        0        0  ...        0   \n",
       "489        0        0        0        0        0        0  ...        0   \n",
       "490        0        0        0        0        0        0  ...        0   \n",
       "491        0        0        0        0        0        0  ...        0   \n",
       "492        0        0        0        0        0        0  ...        0   \n",
       "493        0        0        0        0        0        0  ...        0   \n",
       "494        0        0        0        0        0        0  ...        0   \n",
       "495        0        0        0        0        0        0  ...        0   \n",
       "496        0        0        0        0        0        0  ...        0   \n",
       "497        0        0        0        0        0        0  ...        0   \n",
       "498        0        0        0        0        0        0  ...        0   \n",
       "499        0        0        0        0        0        0  ...        0   \n",
       "500        0        0        0        0        0        0  ...        0   \n",
       "\n",
       "     3/15/20  3/16/20  3/17/20  3/18/20  3/19/20  3/20/20  3/21/20  3/22/20  \\\n",
       "0        114      147      177      212      272      322      411      599   \n",
       "1        839      825      878      889      924      963     1007     1086   \n",
       "2        226      243      266      313      345      385      432      455   \n",
       "3          1        1        1        1        1        1        1        2   \n",
       "4        428      566      673      790      900     1030     1183     1306   \n",
       "5         73      103      103      186      231      271      424      424   \n",
       "6        134      171      210      267      307      353      436      533   \n",
       "7         57       71       94      121      121      121      229      296   \n",
       "8         61       68       78       94      144      184      221      221   \n",
       "9          7        7       33       35       37       51       53       84   \n",
       "10        18       28       44       51       60       73       77       82   \n",
       "11      5795     7272     9257    12327    15320    19848    22213    24873   \n",
       "12       244      277      321      336      400      450      523      626   \n",
       "13        98       98       98      113      140      140      153      153   \n",
       "14       140      142      187      202      217      230      307      380   \n",
       "15       113      119      142      156      194      244      330      396   \n",
       "16     24747    27980    31506    35713    41035    47021    53578    59138   \n",
       "17      1022     1103     1190     1279     1439     1639     1763     1934   \n",
       "18      7798     9942    11748    13910    17963    20410    25374    28768   \n",
       "19        20       29       29       37       42       50       67      100   \n",
       "20       886     1058     1243     1486     1795     2257     2815     3401   \n",
       "21       110      150      196      196      256      285      294      327   \n",
       "22         0        0        0        0        0        0        0        0   \n",
       "23       110       99      120      133      157      163      187      248   \n",
       "24       116      124      154      164      192      208      214      233   \n",
       "25        22       22       24       39       48       48       52       55   \n",
       "26        16       21       22       22       22       24       24       40   \n",
       "27       214      214      228      256      278      285      305      332   \n",
       "28       112      123      130      142      148      159      176      188   \n",
       "29        48       54       60       74       87       90      139      201   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "471        0        0        0        0        0        1        3        3   \n",
       "472        0        0        0        0        0        1        1        1   \n",
       "473        0        0        0        0        0        1        1        2   \n",
       "474        0        0        0        0        0        1        1        1   \n",
       "475        0        0        0        0        0        1        1        5   \n",
       "476        0        0        0        0        0        1        3        3   \n",
       "477        0        0        0        0        0        0        1        1   \n",
       "478        0        0        0        0        0        0        1        1   \n",
       "479        0        0        0        0        0        0        1        1   \n",
       "480        0        0        0        0        0        0        1        1   \n",
       "481        0        0        0        0        0        0        1        1   \n",
       "482        0        0        0        0        0        0        0        1   \n",
       "483        0        0        0        0        0        0        0        1   \n",
       "484        0        0        0        0        0        0        0        1   \n",
       "485        0        0        0        0        0        0        0        1   \n",
       "486        0        0        0        0        0        0        0        1   \n",
       "487        0        0        0        0        0        0        0        0   \n",
       "488        0        0        0        0        0        0        0        0   \n",
       "489        0        0        0        0        0        0        0        0   \n",
       "490        0        0        0        0        0        0        0        0   \n",
       "491        0        0        0        0        0        0        0        0   \n",
       "492        0        0        0        0        0        0        0        0   \n",
       "493        0        0        0        0        0        0        0        0   \n",
       "494        0        0        0        0        0        0        0        0   \n",
       "495        0        0        0        0        0        0        0        0   \n",
       "496        0        0        0        0        0        0        0        0   \n",
       "497        0        0        0        0        0        0        0        0   \n",
       "498        0        0        0        0        0        0        0        0   \n",
       "499        0        0        0        0        0        0        0        0   \n",
       "500        0        0        0        0        0        0        0        0   \n",
       "\n",
       "     3/23/20  \n",
       "0      599.0  \n",
       "1     1086.0  \n",
       "2      455.0  \n",
       "3        2.0  \n",
       "4     1306.0  \n",
       "5      424.0  \n",
       "6      533.0  \n",
       "7      296.0  \n",
       "8      221.0  \n",
       "9       84.0  \n",
       "10      82.0  \n",
       "11   24873.0  \n",
       "12     626.0  \n",
       "13     153.0  \n",
       "14     380.0  \n",
       "15     396.0  \n",
       "16   59138.0  \n",
       "17    1934.0  \n",
       "18   28768.0  \n",
       "19     100.0  \n",
       "20    3401.0  \n",
       "21     327.0  \n",
       "22       0.0  \n",
       "23     248.0  \n",
       "24     233.0  \n",
       "25      55.0  \n",
       "26      40.0  \n",
       "27     332.0  \n",
       "28     188.0  \n",
       "29     201.0  \n",
       "..       ...  \n",
       "471      3.0  \n",
       "472      1.0  \n",
       "473      2.0  \n",
       "474      1.0  \n",
       "475      5.0  \n",
       "476      3.0  \n",
       "477      1.0  \n",
       "478      0.0  \n",
       "479      0.0  \n",
       "480      1.0  \n",
       "481      1.0  \n",
       "482      1.0  \n",
       "483      1.0  \n",
       "484      1.0  \n",
       "485      1.0  \n",
       "486      1.0  \n",
       "487     56.0  \n",
       "488     47.0  \n",
       "489     18.0  \n",
       "490     11.0  \n",
       "491      6.0  \n",
       "492      1.0  \n",
       "493      0.0  \n",
       "494      0.0  \n",
       "495      0.0  \n",
       "496      0.0  \n",
       "497      0.0  \n",
       "498      0.0  \n",
       "499      0.0  \n",
       "500      0.0  \n",
       "\n",
       "[501 rows x 66 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseUrl = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Confirmed_archived_0325.csv\"\n",
    "\n",
    "df = pd.read_csv(baseUrl)\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying \"03-27-2020.csv\"...\n",
      ".... error - 404 not found. Looking for yesterday file\n",
      "Trying \"03-26-2020.csv\"...\n",
      "... Successfully found yesterday file\n"
     ]
    }
   ],
   "source": [
    "baseUrl = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "\n",
    "# Step 1: Get the latest file\n",
    "todaysDate = time.strftime(\"%m-%d-%Y\")\n",
    "todaysFile = todaysDate + \".csv\"\n",
    "dataUrl = baseUrl + todaysFile\n",
    "finalFile = dataUrl;\n",
    "\n",
    "print(f'Trying \"{todaysFile}\"...')\n",
    "response = requests.head(dataUrl, timeout=5);\n",
    "status_code = response.status_code;\n",
    "reason = response.reason;\n",
    "\n",
    "if(status_code != 200):\n",
    "    print('.... error - 404 not found. Looking for yesterday file')\n",
    "\n",
    "    days_to_subtract = 1;\n",
    "    yestDate = datetime.today() - timedelta(days=days_to_subtract);\n",
    "    yestDate = yestDate.strftime(\"%m-%d-%Y\")\n",
    "    yestFile = yestDate + \".csv\"\n",
    "    dataUrl = baseUrl + yestFile\n",
    "\n",
    "    print(f'Trying \"{yestFile}\"...')\n",
    "    response = requests.head(dataUrl, timeout=5);\n",
    "    status_code = response.status_code\n",
    "    reason = response.reason\n",
    "    \n",
    "    if(status_code != 200):\n",
    "        finalFile = \"\";\n",
    "        print(f'... Error! Unable to find yesterday file also')\n",
    "    else:\n",
    "        finalFile = dataUrl;\n",
    "        print('... Successfully found yesterday file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-03-26 23:48:35   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-03-26 23:48:35   \n",
       "2  51001.0   Accomack        Virginia             US  2020-03-26 23:48:35   \n",
       "3  16001.0        Ada           Idaho             US  2020-03-26 23:48:35   \n",
       "4  19001.0      Adair            Iowa             US  2020-03-26 23:48:35   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707          3       0          0       0   \n",
       "1  30.295065  -92.414197          3       0          0       0   \n",
       "2  37.767072  -75.632346          2       0          0       0   \n",
       "3  43.452658 -116.241552         39       0          0       0   \n",
       "4  41.330756  -94.471059          1       0          0       0   \n",
       "\n",
       "                    Combined_Key  \n",
       "0  Abbeville, South Carolina, US  \n",
       "1          Acadia, Louisiana, US  \n",
       "2         Accomack, Virginia, US  \n",
       "3                 Ada, Idaho, US  \n",
       "4                Adair, Iowa, US  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ultimate goal: Get data in 3 column format: Date, Country, TotalConfirmedCasesThusFar\n",
    "\n",
    "# Step 2: Get the raw data\n",
    "# 2020/03/23 - Johns Hopkins changed repo to \n",
    "#      https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports\n",
    "df = pd.read_csv(finalFile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-03-26 23:48:35</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-03-26 23:48:35   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-03-26 23:48:35   \n",
       "2  51001.0   Accomack        Virginia             US  2020-03-26 23:48:35   \n",
       "3  16001.0        Ada           Idaho             US  2020-03-26 23:48:35   \n",
       "4  19001.0      Adair            Iowa             US  2020-03-26 23:48:35   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707          3       0          0       0   \n",
       "1  30.295065  -92.414197          3       0          0       0   \n",
       "2  37.767072  -75.632346          2       0          0       0   \n",
       "3  43.452658 -116.241552         39       0          0       0   \n",
       "4  41.330756  -94.471059          1       0          0       0   \n",
       "\n",
       "                    Combined_Key  \n",
       "0  Abbeville, South Carolina, US  \n",
       "1          Acadia, Louisiana, US  \n",
       "2         Accomack, Virginia, US  \n",
       "3                 Ada, Idaho, US  \n",
       "4                Adair, Iowa, US  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Country_Region\"] == 'US'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 2: Convert date columns to rows\n",
    "df = df.drop(df.columns[[0, 2, 3]], axis=1)\n",
    "\n",
    "# Step 3: Convert dates to invididual rows using melt()\n",
    "key_columns = df.columns.to_list()[:1]\n",
    "date_columns = df.columns.to_list()[1:]\n",
    "\n",
    "df_clean = pd.melt(\n",
    "    df\n",
    "    , id_vars=key_columns\n",
    "    , value_vars=date_columns\n",
    "    , var_name='Date'\n",
    "    , value_name='Confirmed'\n",
    ")\n",
    "\n",
    "# print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country       Date  ConfirmedCases\n",
       "0  Afghanistan 2020-01-22               0\n",
       "1  Afghanistan 2020-01-23               0\n",
       "2  Afghanistan 2020-01-24               0\n",
       "3  Afghanistan 2020-01-25               0\n",
       "4  Afghanistan 2020-01-26               0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Group by Country - remove city/province\n",
    "gbAggs = df_clean.groupby(['Country/Region', 'Date']).agg({\n",
    "        'Confirmed': [\n",
    "            np.sum\n",
    "        ]\n",
    "})\n",
    "\n",
    "# Convert from groupby object to dataframe:\n",
    "gbAggs = gbAggs.reset_index(level=['Country/Region', 'Date'])\n",
    "\n",
    "# Flatten the index by renaming the columns\n",
    "gbAggs.columns = [\"Country\", \"Date\", \"ConfirmedCases\"];\n",
    "gbAggs['Date'] = pd.to_datetime(gbAggs['Date']) \n",
    "gbAggs['ConfirmedCases'] = pd.to_numeric(gbAggs['ConfirmedCases'], downcast='integer')\n",
    "# gbAggs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country       Date  ConfirmedCases\n",
       "176  Algeria 2020-03-21             139\n",
       "177  Algeria 2020-03-22             201\n",
       "178  Algeria 2020-03-23             201\n",
       "239  Andorra 2020-03-22             113\n",
       "240  Andorra 2020-03-23             113"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Remove all rows until a country has at least 100 rows\n",
    "dfFinal = gbAggs[gbAggs[\"ConfirmedCases\"] >= 100]\n",
    "dfFinal = dfFinal.sort_values([\"Country\", \"Date\"]);\n",
    "# dfFinal = dfFinal.set_index(\"Country\", \"Date\");\n",
    "# dfFinal.head()\n",
    "# dfFinal[dfFinal[\"Country\"] == 'US'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target dataframe column format\n",
    "1. 2000-01-01, 'Coca-Cola', '72537'\n",
    "2. 2000-01-01, 'Microsoft', '70196'\n",
    "\n",
    "# Target json data format: \n",
    "1. {date: 2000-01-01, name: \"Coca-Cola\", category: \"Beverages\", value: 72537}\n",
    "2. {date: 2000-01-01, name: \"Microsoft\", category: \"Technology\", value: 70196}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Country\":\"Algeria\",\"Date\":\"2020-03-21T00:00:00.000Z\",\"ConfirmedCases\":139},{\"Country\":\"Algeria\",\"Date\":\"2020-03-22T00:00:00.000Z\",\"ConfirmedCases\":201},{\"Country\":\"Algeria\",\"Date\":\"2020-03-23T00:00:00.000Z\",\"ConfirmedCases\":201},{\"Country\":\"Andorra\",\"Date\":\"2020-03-22T00:00:00.000Z\",\"ConfirmedCases\":113},{\"Country\":\"Andorra\",\"Date\":\"2020-03-23T00:00:00.000Z\",\"ConfirmedCases\":113}]\n"
     ]
    }
   ],
   "source": [
    "# orient 'records' creates one element per row w no index value \n",
    "print(dfFinal.head().to_json(orient='records', date_format='iso'))\n",
    "\n",
    "# Export to file\n",
    "jsonFile = 'temp.json';\n",
    "dfFinal.to_json(jsonFile, orient='records');\n",
    "# https://jsonformatter.curiousconcept.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done - now go use the json file in d3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
